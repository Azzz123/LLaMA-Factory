### model
model_name_or_path: export_results/Llama/un_quantified/Llama-3.1-8B-Instruct
template: llama3
trust_remote_code: true

### export
export_dir: export_results/Llama/gptq/Llama-3.1-8B-Instruct-GPTQ-CMNEE-EE
export_quantization_bit: 4
export_quantization_dataset: data/c4_demo.jsonl
export_size: 3
export_device: auto  # choices: [cpu, auto]
export_legacy_format: false
